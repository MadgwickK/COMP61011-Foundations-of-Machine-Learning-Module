{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptrons in SKlearn and Pytorch\n",
    "\n",
    "The aim of this notebook is to train a simple multilayer perceptron (or feed-forward) neural network using both the sklearn and pytorch libraries. In the **first** part of the notebook, we will provide some sparse template code to train the network. The overall structure should be familiar from last week's lab. If you are stuck, do look over last week's notebook, and refer to the sklearn documentation (as well as asking for demonstrator help). In the **second** part of the notebook, we will use pytorch to do the same thing.\n",
    "\n",
    "We tackle the same problem twice to show how the same problem is treated using the two different libraries. The difference between the two libraries is that sklearn is a general-purpose machine learning library, whereas Pytorch is specfically for deep learning (i.e. neural networks). Sklearn is not intended to be a deep-learning library and does not support parallelisation via GPUs. This means it is fine for relatively small examples (<1000 rows, <50 features, 2-3 hidden layers), but becomes very slow for anything larger.\n",
    "\n",
    "## SKlearn for MLPs\n",
    "Last week, we imported data from the UCI repository. This week, we will start by using data that has been bundled with the sklearn library called 'digits'. The digits dataset is a simplified version of the very famous MNIST data set. This is a set of images, in black and white, of hand-drawn numbers from 0 to 9. Before proceeding, we will look at some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the digits dataset\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b91a256580>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get one image\n",
    "image1 = digits.images[1]\n",
    "plt.imshow(image1, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should understand what the cmap parameter is doing here. If you do not, read the documentation for imshow (via a google search). The data in *images* is stored as a 2-d array, so that the rows and columns of the array match up with the physical coordinates of the image. The data in *data* is stored as a 1-d array, as shown below. You should compare both arrays to ensure you understand how the image data has been converted. From here, we will be working with *data*, as the sklearn functions take a 1-D array as input.\n",
    "\n",
    "Note that this means, for the MLP we will be training, it does not matter which order the image pixels are, as long as they are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. 12. 13.  5.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16.  9.  0.  0.]\n",
      " [ 0.  0.  3. 15. 16.  6.  0.  0.]\n",
      " [ 0.  7. 15. 16. 16.  2.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  3.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16. 10.  0.  0.]]\n",
      "[ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.\n",
      "  3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16.\n",
      " 16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.\n",
      "  0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[1])\n",
    "print(digits.data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us train the MLP. As part of good practice, we scale the digits data. The effect of this is to ensure that any resulting gradients are of a similar scale. This will make the gradient descent process more likely to converge quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaled = preprocessing.scale(digits.data)\n",
    "\n",
    "# split the data into a training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, digits.target, test_size = 0.5)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20,20), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488320355951056"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the process using cross validation, instead of a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 0.96111111 0.96111111 0.95530726 0.94413408]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Using the code above as a template, experiment with changing some of the free parameters:\n",
    "\n",
    "**Q1.** What do you expect to happen if you remove all hidden layers? Modify the neural network using *hidden_layer_sizes* = (). How do you expect this to compare to a logistic regression model? Write you answer below, and test your hypothesis by switching the neural network model for a logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 Answer:**\n",
    "Write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Now modify the neural network to have one hidden layer with 20 nodes. How does the performance compare to the model with no hidden layers and two hidden layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 Answer:** Write answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 (Optional)** Investigate what happens as you increase the number of neurons in a one hidden layer network. Produce an appropriate plot to show the result (for instance, with neurons on the x axis and accuracy on the y axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch for MLPs\n",
    "We will now use the pytorch library to train the same type of neural network. We will start by using the digits dataset to replicate the SKlearn neural network exactly. We will then use a larger dataset of digits (MNIST). Before you undertake this section, you should have completed the *Introduction to Pytorch* notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, including PyTorch\n",
    "If you are using your own computer, you will need to install Pytorch. Setup guidance is here: https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch library (load the neural network module as nn, for convenience to save us writing torch.nn every time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discovered in the previous notebook, pytorch uses tensors as its base unit. So, we will first convert the digits dataset into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_t = torch.from_numpy(X_scaled)\n",
    "#X_scaled_t = torch.transpose(X_scaled_t,0,1)\n",
    "y_t = torch.from_numpy(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we explicitly wrote a function called *model_prediction* that described a linear regression model. We apply the same process here, but the model is a little more complex, so we use some of the inbuilt functions within Pytorch. The following code sets up a 1 hidden layer neural network with 20 neurons.\n",
    "\n",
    "(You may have noticed that we have set up a class, rather than a function (def) here. Broadly, a class is an object that can have many functions applied to it. The nature of an Object is beyond the scope of this course, and if you are interested you should investigate material on object oriented programming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = torch.nn.Linear(input_size,20)\n",
    "        self.fc2 = torch.nn.Linear(20,10)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        output = self.fc2(x)\n",
    "    \n",
    "        return output    # return output of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather that explicitly writing out a loss function, we will use pytorch's inbuilt CrossEntropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a training function - if you compare this to the previous notebook, you should see that it follows the same basic structure as the linear regression example.\n",
    "\n",
    "The only exception is that we set the neural network into *train* mode using mlp.train. This is because some more advanced modifications to a neural network (e.g. batch normalisation) perform differently during training and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, network, X_train, y_train):\n",
    "    \n",
    "    # this sets the model mode - (i.e. layers like dropout, batchnorm etc behave differently during training compared to testing)\n",
    "    # note that this function was not defined explicitly in CNN, but because CNN is a type of nn.Module, it inherits some functions\n",
    "    # from the more general nn class.\n",
    "    network.train()\n",
    "    for epoch in range(num_epochs):   \n",
    "        output = network(X_train) # this is the model prediction\n",
    "        loss = loss_func(output, y_train) # evaluate the loss (error)\n",
    "            \n",
    "        # clear gradients for this training step   \n",
    "        optimizer.zero_grad()           \n",
    "            \n",
    "        # backpropagation, compute gradients \n",
    "        loss.backward()    \n",
    "        # apply gradients             \n",
    "        optimizer.step()                \n",
    "            \n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch + 1, num_epochs, loss.item()))\n",
    "        #    pass     \n",
    "        pass\n",
    "    pass\n",
    "\n",
    "    # print the predicted (and true) labels after training. Note that raw output of the neural network is a score for each class, so we use argmax\n",
    "    # to return the class with the highest score\n",
    "    print(torch.argmax(output,1))\n",
    "    print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.3164\n",
      "Epoch [2/50], Loss: 2.2854\n",
      "Epoch [3/50], Loss: 2.2559\n",
      "Epoch [4/50], Loss: 2.2276\n",
      "Epoch [5/50], Loss: 2.2000\n",
      "Epoch [6/50], Loss: 2.1730\n",
      "Epoch [7/50], Loss: 2.1462\n",
      "Epoch [8/50], Loss: 2.1196\n",
      "Epoch [9/50], Loss: 2.0929\n",
      "Epoch [10/50], Loss: 2.0662\n",
      "Epoch [11/50], Loss: 2.0392\n",
      "Epoch [12/50], Loss: 2.0119\n",
      "Epoch [13/50], Loss: 1.9843\n",
      "Epoch [14/50], Loss: 1.9565\n",
      "Epoch [15/50], Loss: 1.9284\n",
      "Epoch [16/50], Loss: 1.9001\n",
      "Epoch [17/50], Loss: 1.8716\n",
      "Epoch [18/50], Loss: 1.8430\n",
      "Epoch [19/50], Loss: 1.8143\n",
      "Epoch [20/50], Loss: 1.7855\n",
      "Epoch [21/50], Loss: 1.7567\n",
      "Epoch [22/50], Loss: 1.7279\n",
      "Epoch [23/50], Loss: 1.6991\n",
      "Epoch [24/50], Loss: 1.6703\n",
      "Epoch [25/50], Loss: 1.6416\n",
      "Epoch [26/50], Loss: 1.6130\n",
      "Epoch [27/50], Loss: 1.5845\n",
      "Epoch [28/50], Loss: 1.5560\n",
      "Epoch [29/50], Loss: 1.5277\n",
      "Epoch [30/50], Loss: 1.4996\n",
      "Epoch [31/50], Loss: 1.4717\n",
      "Epoch [32/50], Loss: 1.4439\n",
      "Epoch [33/50], Loss: 1.4164\n",
      "Epoch [34/50], Loss: 1.3891\n",
      "Epoch [35/50], Loss: 1.3621\n",
      "Epoch [36/50], Loss: 1.3354\n",
      "Epoch [37/50], Loss: 1.3090\n",
      "Epoch [38/50], Loss: 1.2829\n",
      "Epoch [39/50], Loss: 1.2571\n",
      "Epoch [40/50], Loss: 1.2316\n",
      "Epoch [41/50], Loss: 1.2065\n",
      "Epoch [42/50], Loss: 1.1818\n",
      "Epoch [43/50], Loss: 1.1574\n",
      "Epoch [44/50], Loss: 1.1335\n",
      "Epoch [45/50], Loss: 1.1099\n",
      "Epoch [46/50], Loss: 1.0867\n",
      "Epoch [47/50], Loss: 1.0639\n",
      "Epoch [48/50], Loss: 1.0415\n",
      "Epoch [49/50], Loss: 1.0195\n",
      "Epoch [50/50], Loss: 0.9979\n",
      "tensor([0, 1, 1,  ..., 1, 9, 8])\n",
      "tensor([0, 1, 2,  ..., 8, 9, 8])\n"
     ]
    }
   ],
   "source": [
    "input_size = X_scaled_t.size(1) # input size is the same size as a digits image (8x8)\n",
    "mlp = MLP(input_size) # set up an instance of the MLP object\n",
    "mlp = mlp.double()\n",
    "\n",
    "# use the adam optimiser to do the updates - this is a modern update to classic stochastic gradient descent\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(mlp.parameters(), lr = 0.005)\n",
    "\n",
    "# call the training function and run over 1000 epochs\n",
    "num_epochs = 50\n",
    "train(num_epochs, mlp, X_scaled_t, y_t.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "**Q1** Has the model finished training? (How can you tell whether it has or not?)\n",
    "\n",
    "**Q2** Modify the *train* function above to dynamically set the number of training epochs, depending on the change in loss between iterations\n",
    "\n",
    "**Q3** The size (number of neurons) of the hidden layer is 20. Try changing this - how does this affect the loss?\n",
    "\n",
    "**Q4** Try adding an additional hidden layer of size 20 - you will need to make sure that the size of the inputs and outputs of each layer match up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
