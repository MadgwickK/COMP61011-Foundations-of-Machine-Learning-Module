{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf14062-4833-4402-8fac-d804c5f1e3a6",
   "metadata": {},
   "source": [
    "# Notebook 1 - Machine Learning with SKLearn\n",
    "\n",
    "SKLearn is a library (set of functions) that are useful for machine learning. It includes a range of machine learning models, including the Logistic Regression and Perceptron that you have already used. Unlike the implementation that you saw last week, the finer details of the algorithm are hidden away, making this library much easier to use.\n",
    "\n",
    "In practice, you would never choose to write machine learning algorithms from scratch, and instead rely on libraries like SKlearn (or pytorch, for instance, for neural networks). In this session, we will first introduce you to the basic structure of training a machine learning model using SKLearn. In the second notebook, End-to-end Machine Learning, we will go through a typicaly selection of functions that one would use to fully train a model, including pre-processing.\n",
    "\n",
    "Hopefully, in this process, you will see that training and switching between different Machine Learning models is very simple.\n",
    "\n",
    "In the third (and final) notebook, we provide a skeleton set of tasks, to guide you through performing end-to-end machine learning on a new set of data.\n",
    "\n",
    "## Import some data\n",
    "For this simple example, we are going to import a small data set that has been included with the SKlearn library for teaching purposes. In real life (and indeed, in notebook 2 and 3), we would typically import our data from an external file.\n",
    "\n",
    "Here, we will not consider any data pre-processing - we assume (rightly or wrongly) that the dataset is ready to be input into a machine learning model. The only thing that we will do is split the data into a training set (70%) and a test set (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f58b7131-6689-46c0-ad32-3e42a7d4c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from the sklearn library\n",
    "# note that we're not importing the whole sklearn library - just the functions we want\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2] # in this case, there are 4 features in the iris data set, but we only use 2, and 150 examples. You can check this by running X.shape\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# setting the random_state to a fixed values means that the split between train and test is consistent between runs.\n",
    "# This is useful to check that our code is running properly, but we might want to remove if we were checking variability (for instance) over multiple runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5873c2-db14-4894-8bc8-7a863b07e84a",
   "metadata": {},
   "source": [
    "We then instantiate our machine learning model. In this case we, use Logistic Regression. The full list of models included in SKLearn can be found in the documentation: https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5106b7c0-83a7-4d1d-b62e-317a602b4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca168a09-787c-4f36-8a65-cd6d5ec5d203",
   "metadata": {},
   "source": [
    "After we have created an empty instance of the model, we apply it to our data using the .fit command. This trains the model. We can look at the impact of our model using the .predict command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962b8550-ec7f-4309-aa97-51969f2f3f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af455bfd-9a70-40ce-87e7-70c3c33742a2",
   "metadata": {},
   "source": [
    "Note that this procedure of .fit and .predict is always the same for sklearn. For instance, we can choose a different machine learning model, and apply the same fitting and predicting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b01f0e14-818e-431d-815a-1c3fa0261171",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptronModel = Perceptron()\n",
    "perceptronModel.fit(X_train, y_train)\n",
    "y_preds_perceptron = perceptronModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4e30e-90db-4c85-964a-fd4e92b92a96",
   "metadata": {},
   "source": [
    "SKlearn also has a number of inbuilt functions to report metrics that help us to assess the performance of a machine learning model. A number of them are calculated below, and their meaning should be self-explanatory (following on from the lectures this week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ed27164-8e29-48bc-a731-85cb8a99cbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58e72a7-c231-4853-9acd-6daa6131365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.78      0.54      0.64        13\n",
      "           2       0.65      0.85      0.73        13\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.81      0.79      0.79        45\n",
      "weighted avg       0.83      0.82      0.82        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2eb97a7-f22c-469b-98b1-96f63f58f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0  7  6]\n",
      " [ 0  2 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabec350-27c3-4a03-8d8f-8f83d29a093f",
   "metadata": {},
   "source": [
    "That's all for this notebook. You should ensure that you are comfortable with this training process, and you may wish to convince yourself that this training process is consistent in sklearn by trying some other machine learning classification models (note that you can apply these even if you do not know what they are doing under-the-hood!).\n",
    "\n",
    "You may also wish to see what happens if you use the whole data set, rather than just 2 of the 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d5a1a-023d-45d0-bc06-8c75817d15ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
