{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f70545-b995-4d95-885e-c562c1643f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training a CNN with Pytorch\n",
    "We will now be using a expanded version of the digits data set to train a convolutional neural network.\n",
    "\n",
    "We will again be using the Pytorch library. As you will have seen from the previous notebook, in comparison to sklearn, Pytorch provides much more control over the architecture of your neural network. We will be making use of this here.\n",
    "\n",
    "As before, we load the libraries that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b609b7-869f-4ebd-ad08-8e961b0fe73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a012c-638d-4ec0-8771-4efb2a6bdad8",
   "metadata": {},
   "source": [
    "The next lines check if your computer has CUDA GPU capabilities and uses it if it can. The lab computires fon't have GPUs. This means that the model will still train, but it will be slower than it could be. Everything should still run within a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd9d008-6f39-4e37-8974-e64cb5ea1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c77cbd-c7f6-44de-b385-25c00831d5aa",
   "metadata": {},
   "source": [
    "## Import some data\n",
    "Like sklearn, PyTorch has some built in datasets. We will be using the MNIST digits data set, which is a larger version (in both image size and image quantity) of the sklearn digits dataset. Note that the code snippet below creates two dataset objects, one which is training data (train = True) and the other that is test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a4d6df-97cd-407b-827c-7e951b9c49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    "    )\n",
    "    \n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2a0ca-115c-456b-ac5d-74388faaef60",
   "metadata": {},
   "source": [
    "## View basic data set information\n",
    "Now that the dataset has been imported, you can view information about the train/test set using print(train_data) if you wish. You will see that there are 60000 training examples and 10000 test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab61409-5bec-4d34-8639-c1e434d31d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a43446-f966-477a-843e-234facef57fc",
   "metadata": {},
   "source": [
    "Like the Sklearn task, let's plot one of the images to see what we're looking at. Note that these are grayscale images (i.e. different shades of grey) rather than full RGB colour images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8b0a09-dab4-4e36-bbd0-046e5fc18abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[0], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2fe17f-d5ec-47b4-af1d-e792e36f3082",
   "metadata": {},
   "source": [
    "# Create the convolutional neural network architecture as a new class, CNN\n",
    "\n",
    "The CNN class below creates the neural network architecture. This structure is a little bit more complicated than the multi-layer perceptron. In particular, we now incorporate convolution and maxpooling layers. These are built-in to Pytorch, so we do not need to define them from scratch.\n",
    "\n",
    "For ease of reading, we group sets of neural network operations (layers) together via the nn.sequential function. So, *conv1* consists of a conv2d layer, a ReLU activation and a max pooling layer. Each layer type has its own parameters (in_channels, out_channels, etc.)\n",
    "\n",
    "In conv1, the convolution (conv2d) layer, we create 16 convolution filters (out_channels), a free choice by us. \n",
    "\n",
    "In the 2nd set of convolutions, defined by *conv2*, we have 16 convolutions from *conv1*, so our first parameter is 16 and we choose to have 32 output filters. Note that, for *conv2*, the parameters have been written in shorthand, without explicitly referring to the parameter variable name.\n",
    "\n",
    "The function, forward, describes how the whole network is put together from its component layers. It shows how we first put our input through *conv1*, then *conv2*, then *out* (a fully connected layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb3117cd-2256-4859-9b4b-2cab285f5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=8,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(8, 16, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(16 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180fc06-a45d-4777-ba0c-141e2b9f63f8",
   "metadata": {},
   "source": [
    "## instantiate the neural network object\n",
    "The class code above describes what our CNN object looks like, but we need to actual create an instance of the object. We do a similar thing when we train models in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf63a0e-221d-472d-afea-e6aa0b11facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN() # note that the variable name can be anything here, but I've chosen cnn for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50797625-2306-4761-b571-f44c02deec45",
   "metadata": {},
   "source": [
    "# Define the loss function and optimizer \n",
    "We now define the loss function and optimizer to train the network. Unlike standard stochastic gradient descent (what we looked at in the lectures), Adam is a variant that uses an adaptive learning rate to allow for faster convergence in many situations.\n",
    "\n",
    "We set the initial learning rate at 0.01. This is quite large and may lead to non-convergence in other problems, but in this case I know it works (through trial and error), and it means that we will be abel to see the impact of training in relatively few iterations\n",
    "\n",
    "We use the cross entropy loss, which is the go-to for classification problems, rather than something like the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70a38e1a-7ede-458b-b4fc-974bc5ce87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()   \n",
    "from torch import optim\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839952f-df64-438b-b5b6-9a0c2bb96528",
   "metadata": {},
   "source": [
    "# Set up training parameters\n",
    "\n",
    "When we used Pytorch in the previous notebook, we used all of the data (i.e. full gradient descent). However, Pytorch gives us the ability to perform gradient descent, using a pre-specified batch size. This is taken care of by the dataloader utility\n",
    "\n",
    "the *batch_size* sets the mini-batch used in SGD (i.e. how many examples are considered at each step - in the lectures, we consider one example at a time, so-called online SGD). *shuffle* shuffles the data at each epoch, to reduce the likelihood of weird local convergence. This might happen, for instance, if all of the digits are in order, so that all of the 1s are trained first. This could lead to a situation where the network thinks that it has finished training because it sees thousands of examples of 1s, and only trains to recognise 1s. *num_workers* relates to how the data is handled in the memory (e.g. whether there are multiple sub-processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ad48999-e60b-435b-8f82-efee7ad04376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2),\n",
    "    \n",
    "    'test'  : DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bceb8-402c-4b30-82e2-f7ac0b613fb6",
   "metadata": {},
   "source": [
    "## training function\n",
    "We now define how model training works, over num_epochs. Note how the loss is computed. Gradients are computed useing loss.backward, and then weights are updated using optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f730cb9f-61cd-40d6-aaaf-1efa1d1a25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    # this sets the model mode - (i.e. layers like dropout, batchnorm etc behave differently during training compared to testing)\n",
    "    # note that this function was not defined explicitly in CNN, but because CNN is a type of nn.Module, it inherits some functions\n",
    "    # from the more general nn class.\n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "       \n",
    "            b_x = images\n",
    "            b_y = labels\n",
    "            \n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "            pass     \n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fafb8-f75e-4782-8a25-3ff8ab35a59a",
   "metadata": {},
   "source": [
    "After you have run everything above, call the training function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bad724a7-f289-46a0-9b08-e33305d208d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.1035\n",
      "Epoch [1/2], Step [200/600], Loss: 0.1141\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1043\n",
      "Epoch [1/2], Step [400/600], Loss: 0.0720\n",
      "Epoch [1/2], Step [500/600], Loss: 0.0762\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0503\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0832\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0460\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1262\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0066\n",
      "Epoch [2/2], Step [500/600], Loss: 0.0134\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0786\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4363c02-178f-4aa0-a7d0-27dc3587acbf",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "In a standard gradient descent, you would expect the training loss to go down consistently. However, we are estimating the gradient each time on a subset of the data. This means that training loss can go up as well as down - however, over enough time, it can be shown that it will converge. One of the big advantages is that SGD requires a lot less memory, as we deal with only a small number of training examples at a time.\n",
    "\n",
    "Now that the model has trained, let's see how well it does...\n",
    "\n",
    "Note that the CNN model does not have a sigmoid (or softmax) activation layer at the very end - this means that the outputs are not bound between 0 and 1. For more info on why we do this, search the documentation for CrossEntropyLoss vs BCEWithLogitsLoss.\n",
    "\n",
    "If we wanted the *probability* of each class, we would need to add a softmax layer to the output. In this case, we just care about the most likely class, so we can just select the index that corresponds to the highest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef73a1ab-3d70-4ad7-81f6-9f87f7cfd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.98\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images) ## this runs the trained cnn. Note from the cnn class, test_output gives the model output (10 x 1 values), and last_layer gives the inputs into the last layer\n",
    "            ## torch.max finds the highest value of test_output. the [0] array element returns the maximum value, the [1] element\n",
    "            ## gives the index of that element. squeeze reshapes the data from a nx1 array into a list\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze() \n",
    "            #print(pred_y)\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "        pass\n",
    "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "    \n",
    "    pass\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4723fd2-dcf4-4fe6-8527-10c88e02ac0c",
   "metadata": {},
   "source": [
    "## Questions\n",
    "**Q1** What steps might you take to improve the performance of the model. Modify the training code with your idea. It should be possible to attain an accuracy of 1.00 on this data set.\n",
    "\n",
    "**Q2** Try adding an additional layer that contains a convolution, Relu activation, and maxpooling. Copy and paste the CNN class above so that you have a clean copy. By sure to consider the input and output size of the new layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
